<h1>Колмогоровская сложность</h1>

<p>Вычисление Колмогоровской сложности для некоторой строки данных (которая, в общем случае, невычислима) — это нахождение такого описания строки на некотором алгоритмическом языке, которое занимает минимальный возможный размер.</p>

<p><img src="http://www.scottaaronson.com/coffee-small.jpg" alt="Complexity dinamics" title="Complexity dinamics"></p>

<p>По сути можно сказать, что задачей машинного обучения является именно нахождение такого рода алгоритмических закономерностей в самом перспективном случае.
На практике, однако, реализация такого рода обучения невозможна и приходится пользоваться таким критерием, как максимизация информационной энтропии.
Здесь, однако, нужно привести пример, ради которого и написана эта короткая заметка: рассмотрим генератор псевдослучайных чисел, например, регистр сдвига с линейной обратной связью.
Такого рода ГПСЧ может генерировать не повторяющиеся последовательности длинной до \(2^n\) чисел.
Так как распределение чисел равномерно, то, подсчитав энтропию, мы получим достаточно большое значение. Колмогоровская же сложность будет существенно меньше, чем количество информации, оценённой как произведение энтропии на количество символов в сообщении, что очевидно из способа построения самого ГПСЧ.</p>
